{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# AlphaGo Zero: Mastering the game of Go without human knowledge\n",
    "\n",
    "New reinforcement learning algorithm that incorporates lookahead search inside the training loop, resulting in rapid improve­ ment and precise and stable learning."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The outstanding idea behind AlphaGo Zero (it is ridiculously elegant)\n",
    "\n",
    "Deep neural network that uses the raw board representations of the position and its history and outputs both move probabilities and\n",
    "a value estimating the probability of the current player winning from this position.\n",
    "\n",
    "What makes the algorithm so elegant is that it uses the following simple mantra for learning:\n",
    "\n",
    "1. Mentally play through possible future scenarios, giving priority to promising paths, whilst also considering how others are most likely to react to your actions and continuing to explore the unknown.\n",
    "\n",
    "2. After reaching a state that is unfamiliar, evaluate how favourable you believe the position to be and cascade the score back through previous positions in the mental pathway that led to this point.\n",
    "\n",
    "3. After you’ve finished thinking about future possibilities, take the action that you’ve explored the most.\n",
    "\n",
    "4. At the end of the game, go back and evaluate where you misjudged the value of the future positions and update your understanding accordingly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reinforcement Learning in AlphaGo Zero\n",
    "\n",
    "Neural network trained from games of self-play by a novel RL algorithm (Self-play combined with MCTSl search). MCTS search guided by neural\n",
    "network.\n",
    "\n",
    "What is the goal of the neural network and how is it connected with MCTS?\n",
    "\n",
    "Main parts of the learning process should somehow explain the 4\n",
    "\n",
    "Illustration showing the whole process.\n",
    "\n",
    "We should focus on this section here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exemplary results\n",
    "\n",
    "Show some exemplary results using the Python and Keras Implementation.\n",
    "Compare the Performance of AlphaGo Zero to previous variants like AlphaGo Master and AlphaGo Lee"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "\n",
    "- [Github](https://github.com/AppliedDataSciencePartners/DeepReinforcementLearning)\n",
    "- [AlphaZero Cheatsheet](https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0)\n",
    "- [AlphaZero using Python and Keras](https://medium.com/applied-data-science/how-to-build-your-own-alphazero-ai-using-python-and-keras-7f664945c188)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}