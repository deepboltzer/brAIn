{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradient\n",
    "\n",
    "- goal to optimize the policy\n",
    "- previous approaches need to analyze entire action space\n",
    "- curse of dimensionality\n",
    "- idea to approximate the direction of the optimal policy using the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient ascent\n",
    "\n",
    "- observe gradient $\\nabla_\\theta J \\left(\\theta\\right)$\n",
    "- gradient always points to the direction of greatest growth\n",
    "- by adjusting $\\theta$ according to the gradient policy $\\pi$ can be optimized\n",
    "\n",
    "// beliebig detailiert\n",
    "// vielleicht um stochastic gradient ascent erg√§nzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient Theorem\n",
    "\n",
    "- gradient's calculation may be very complex\n",
    "- policy gradient theorem simplifies it's computation as follows\n",
    "\n",
    "\\begin{align*}\n",
    "    \\nabla_\\theta J \\left(\\theta\\right) &= \\nabla_\\theta \\sum_{s \\in S} d^\\pi (s) \\sum_{a \\in A} Q^\\pi (s, a) \\pi_\\theta (a|s) \\newline\n",
    "    &\\propto \\sum_{s \\in S} d^\\pi (s) \\sum_{a \\in A} Q^\\pi (s, a) \\nabla_\\theta \\pi_\\theta (a|s)\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCE (Monte-Carlo policy gradient) Algorithm\n",
    "\n",
    "[...]\n",
    "\n",
    "Pseudoalgorithm:\n",
    "\n",
    "1. Initialize the policy parameter $\\theta$ at random.\n",
    "2. Generate one trajectory on policy $\\pi_\\theta: S_1, A_1, R_2, S_2, A_2, ..., S_T$\n",
    "3. For $t=1, 2, ..., T:$\n",
    "    1. Estimate the return $G_T$;\n",
    "    2. Update policy parameters: $\\theta \\leftarrow \\theta + \\alpha\\gamma^t G_t \\nabla_\\theta ln_{\\pi_\\theta}\\left( A_t | S_t \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Policy Gradient Algorithms by Lilian Weng](https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
