# Additional Ressources 

- [BAIR University of Berkley](https://bair.berkeley.edu/blog/2020/03/27/attacks/)
- [Adversarial Policies Summary](https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Adversarial_RL.md)
- [Implementation Attacks](https://github.com/davide97l/rl-policies-attacks-defenses)
- Implement DQN, A2C and PPO
- [Implementation of A2C and PPO](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail)
- [Open AI ACKTR & A2C](https://openai.com/blog/baselines-acktr-a2c/)
- [Open AI PPO](https://openai.com/blog/openai-baselines-ppo/)
- [DQN Tianshu](https://github.com/thu-ml/tianshou)
- [multiagent-competition (used in Berkley paper)](https://github.com/openai/multiagent-competition)
- [openAI spinning up policy Gradient implementation](https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html)
