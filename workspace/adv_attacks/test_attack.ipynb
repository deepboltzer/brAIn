{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo.policies import CnnPolicy\n",
    "from stable_baselines3.ppo.policies import MlpPolicy\n",
    "from utils.adversary_env import AdversaryEnv\n",
    "from utils.adversary_wrapper import AdversaryWrapper\n",
    "\n",
    "# Load target model\n",
    "target_model = A2C.load(\"../a2c/model/lunarlander_v2_a2c_3M_to_11M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adversary with adversary wrapper\n",
    "# adversary_env = AdversaryWrapper(env=gym.make('LunarLander-v2'))\n",
    "# adversary_env.set_model(target_model)\n",
    "# adversary = PPO(MlpPolicy, adversary_env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Create adversary with adversary env\n",
    "# adversary_env = AdversaryEnv(\"LunarLander-v2\", target_model)\n",
    "# adversary = PPO(MlpPolicy, adversary_env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 83.2     |\n",
      "|    ep_rew_mean     | 165      |\n",
      "| time/              |          |\n",
      "|    fps             | 336      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.4        |\n",
      "|    ep_rew_mean          | 181         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009137257 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 7.87e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 865         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.51e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.3        |\n",
      "|    ep_rew_mean          | 186         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008671166 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.000108    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 467         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 1.51e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.9         |\n",
      "|    ep_rew_mean          | 178          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073031764 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | 2.56e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 573          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00757     |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80          |\n",
      "|    ep_rew_mean          | 178         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009265452 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 1.01e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 773         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.2        |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010059398 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | -9.42e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 379         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 836         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.8       |\n",
      "|    ep_rew_mean          | 169        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00932062 |\n",
      "|    clip_fraction        | 0.073      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.2      |\n",
      "|    explained_variance   | -8.94e-06  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 375        |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00829   |\n",
      "|    std                  | 0.979      |\n",
      "|    value_loss           | 965        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 175         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009878164 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 1.6e-05     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 646         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 849         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 170         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008784866 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -1.35e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 328         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 707         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.6       |\n",
      "|    ep_rew_mean          | 170        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01344687 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.1      |\n",
      "|    explained_variance   | 2.74e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 214        |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.00493   |\n",
      "|    std                  | 0.972      |\n",
      "|    value_loss           | 583        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.9        |\n",
      "|    ep_rew_mean          | 193         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005161646 |\n",
      "|    clip_fraction        | 0.0231      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 1.51e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 228         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    std                  | 0.971       |\n",
      "|    value_loss           | 576         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.1         |\n",
      "|    ep_rew_mean          | 209          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 266          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047587454 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.1        |\n",
      "|    explained_variance   | 6.26e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 457          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 1.15e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76           |\n",
      "|    ep_rew_mean          | 249          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 266          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060960157 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.1        |\n",
      "|    explained_variance   | 7.99e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 512          |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00705     |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 1.2e+03      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 76.1       |\n",
      "|    ep_rew_mean          | 289        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 108        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00522383 |\n",
      "|    clip_fraction        | 0.0202     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.1      |\n",
      "|    explained_variance   | 8.58e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 885        |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.00562   |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 1.65e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.6        |\n",
      "|    ep_rew_mean          | 325         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004956709 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 7.51e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 980         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 2.38e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 75.7         |\n",
      "|    ep_rew_mean          | 352          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 264          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059391614 |\n",
      "|    clip_fraction        | 0.0488       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.1        |\n",
      "|    explained_variance   | 3.93e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00794     |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 2.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 74.9         |\n",
      "|    ep_rew_mean          | 372          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 264          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059969355 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.1        |\n",
      "|    explained_variance   | 3.99e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 2.2e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73          |\n",
      "|    ep_rew_mean          | 374         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004993944 |\n",
      "|    clip_fraction        | 0.0263      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 3.58e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 2.89e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.6        |\n",
      "|    ep_rew_mean          | 393         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008317532 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 2.38e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 3e+03       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.4        |\n",
      "|    ep_rew_mean          | 412         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008206894 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 1.67e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 2.82e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.8        |\n",
      "|    ep_rew_mean          | 435         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006639371 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 1.67e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    std                  | 0.96        |\n",
      "|    value_loss           | 3.65e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 72           |\n",
      "|    ep_rew_mean          | 456          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 264          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077377795 |\n",
      "|    clip_fraction        | 0.0672       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11          |\n",
      "|    explained_variance   | 9.54e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.32e+03     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00732     |\n",
      "|    std                  | 0.958        |\n",
      "|    value_loss           | 4.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71.8         |\n",
      "|    ep_rew_mean          | 471          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 264          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 177          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069948686 |\n",
      "|    clip_fraction        | 0.0797       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11          |\n",
      "|    explained_variance   | 1.25e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.71e+03     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00884     |\n",
      "|    std                  | 0.957        |\n",
      "|    value_loss           | 4.14e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.4        |\n",
      "|    ep_rew_mean          | 487         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006971777 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 9.54e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.43e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    std                  | 0.953       |\n",
      "|    value_loss           | 4.19e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71           |\n",
      "|    ep_rew_mean          | 497          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 264          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041185445 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11          |\n",
      "|    explained_variance   | 5.36e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05e+03     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    std                  | 0.95         |\n",
      "|    value_loss           | 4.4e+03      |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train adversary\n",
    "# log_dir = \"./out/training-log/\"\n",
    "# log_path = log_dir + f\"adversary-lunarlander-v2/\"\n",
    "# save_dir = \"./models/adversary-lunarlander-v2/\"\n",
    "\n",
    "# timesteps = 50000\n",
    "\n",
    "# adversary.learn(\n",
    "#         total_timesteps=timesteps\n",
    "#         )\n",
    "\n",
    "# # Save adversary\n",
    "# adversary.save(save_dir + f\"adversary_lunarlander_v2_{timesteps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load adversary\n",
    "log_dir = \"./out/training-log/\"\n",
    "log_path = log_dir + f\"adversary-lunarlander-v2/\"\n",
    "save_dir = \"./models/adversary-lunarlander-v2/\"\n",
    "\n",
    "adversary = PPO.load(save_dir + f\"adversary_lunarlander_v2_50000\")\n",
    "adversary_env = AdversaryEnv(\"LunarLander-v2\", target_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mg:\\data\\documents\\university\\projektgruppe-kivs\\brAIn\\workspace\\adv_attacks\\test_attack.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/test_attack.ipynb#ch0000005?line=2'>3</a>\u001b[0m \u001b[39m# Run attack on a2c model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/test_attack.ipynb#ch0000005?line=3'>4</a>\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mmake(\u001b[39m\"\u001b[39m\u001b[39mLunarLander-v2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/test_attack.ipynb#ch0000005?line=4'>5</a>\u001b[0m ua \u001b[39m=\u001b[39m UniformAttack(env\u001b[39m=\u001b[39;49menv, model\u001b[39m=\u001b[39;49mtarget_model, attack\u001b[39m=\u001b[39;49madversary)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/test_attack.ipynb#ch0000005?line=5'>6</a>\u001b[0m ua\u001b[39m.\u001b[39mperform_attack()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/test_attack.ipynb#ch0000005?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTotal reward achieved: \u001b[39m\u001b[39m{\u001b[39;00mua\u001b[39m.\u001b[39mreward_total\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mg:\\data\\documents\\university\\projektgruppe-kivs\\brAIn\\workspace\\adv_attacks\\uniform_attack.py:11\u001b[0m, in \u001b[0;36mUniformAttack.__init__\u001b[1;34m(self, env, model, attack)\u001b[0m\n\u001b[0;32m     <a href='file:///g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/uniform_attack.py?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, env, model, attack):\n\u001b[1;32m---> <a href='file:///g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/uniform_attack.py?line=10'>11</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(env, model, attack)\n",
      "File \u001b[1;32mg:\\data\\documents\\university\\projektgruppe-kivs\\brAIn\\workspace\\adv_attacks\\base_attack.py:22\u001b[0m, in \u001b[0;36mBaseAttack.__init__\u001b[1;34m(self, env, model, attack, epsilon, device)\u001b[0m\n\u001b[0;32m     <a href='file:///g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/base_attack.py?line=18'>19</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepsilon \u001b[39m=\u001b[39m epsilon\n\u001b[0;32m     <a href='file:///g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/base_attack.py?line=19'>20</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m AttackData()\n\u001b[1;32m---> <a href='file:///g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/base_attack.py?line=21'>22</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_env()\n\u001b[0;32m     <a href='file:///g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/base_attack.py?line=23'>24</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m# total cumulative episode reward\u001b[39;00m\n\u001b[0;32m     <a href='file:///g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/base_attack.py?line=24'>25</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframes_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m# current number of frames/timesteps in current episode\u001b[39;00m\n",
      "File \u001b[1;32mg:\\data\\documents\\university\\projektgruppe-kivs\\brAIn\\workspace\\adv_attacks\\base_attack.py:30\u001b[0m, in \u001b[0;36mBaseAttack.reset_env\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/base_attack.py?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset_env\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='file:///g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/base_attack.py?line=28'>29</a>\u001b[0m     \u001b[39m\"\"\"Resets the environment and collects the observation.\"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///g%3A/data/documents/university/projektgruppe-kivs/brAIn/workspace/adv_attacks/base_attack.py?line=29'>30</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mset_last_obs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mreset())\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "from uniform_attack import UniformAttack\n",
    "\n",
    "# Run attack on a2c model\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "ua = UniformAttack(env=env, model=target_model, attack=adversary)\n",
    "ua.perform_attack()\n",
    "print(f\"Total reward achieved: {ua.reward_total}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1eaab1189d37ae29f7eac77705a074d5028424b72ba552afc8bf8536055072c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch-gym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
